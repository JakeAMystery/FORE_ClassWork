{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMypTEwZaRUiLx/pIWXmNm7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JakeAMystery/FORE_ClassWork/blob/main/CPAI/CPAI_Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V7yatVsv2ouM"
      },
      "outputs": [],
      "source": [
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mount drive at /gdrive:\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9sMaJLv7bjb",
        "outputId": "2f98c06f-c6ec-4cf2-98e1-a42daaafefe3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1.1 Call libraries for image processing\n",
        "#     Another preprocessing option is text and sequence\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 1.2, Libraries for building sequential CNN model\n",
        "#      A model is composed of sequence of layered objects\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Input\n",
        "\n",
        "# 1.5 OS related\n",
        "import os\n",
        "\n",
        "# 1.6 For ROC plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1.7\n",
        "import numpy as np\n",
        "# conda install scikit-learn\n",
        "from sklearn import metrics\n",
        "import time\n"
      ],
      "metadata": {
        "id": "ajcjuuz17j5u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 2. Our constants\n",
        "# 2.1 Dimensions to which our images will be adjusted\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "# 2.2 Data folder containing all training images, maybe in folders: cats and dogs\n",
        "\n",
        "train_data_dir = \"/gdrive/MyDrive/Capstone Project in AI/data/train\"\n",
        "test_data_dir =  \"/gdrive/MyDrive/Capstone Project in AI/data/validation\"\n",
        "\n",
        "# 2.3 What is the total number of training images\n",
        "#      that should be generated (not what are available)\n",
        "nb_train_samples = 989\n",
        "\n",
        "# 2.5 What is the total no of validation samples that should\n",
        "#     be generated?\n",
        "nb_validation_samples = 140\n",
        "\n",
        "# Some hyperparameters\n",
        "\n",
        "# 2.6 Batch size to train at one go:\n",
        "batch_size = 32\n",
        "\n",
        "# 2.7 How many epochs of training?\n",
        "epochs = 5\n",
        "\n",
        "# 2.8 No of test samples\n",
        "test_generator_samples = 300\n",
        "\n",
        "# 2.9 For test data, what should be batch size\n",
        "test_batch_size = 32\n",
        "\n",
        "# 2.10\n",
        "input_shape = (img_width, img_height, 3)\n"
      ],
      "metadata": {
        "id": "bjfwuymz8MLh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "IzrzHYTX9-b5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = Sequential()\n",
        "model_1.add(Input(shape=input_shape))\n",
        "\n",
        "model_1.add(Conv2D(\n",
        "    filters=64,\n",
        "    kernel_size= (3,3),\n",
        "    padding='same',\n",
        "    activation= 'relu'\n",
        "))\n",
        "model_1.add(MaxPool2D())\n",
        "\n",
        "model_1.add(Conv2D(\n",
        "    filters=64,\n",
        "    kernel_size= (3,3),\n",
        "    activation= 'relu'\n",
        "))\n",
        "model_1.add(MaxPool2D())\n",
        "\n",
        "model_1.add(Conv2D(\n",
        "    filters=32,\n",
        "    kernel_size= (3,3),\n",
        "    activation= 'relu'\n",
        "))\n",
        "\n",
        "model_1.add(Flatten())\n",
        "\n",
        "model_1.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK-Gl3vb99Ub",
        "outputId": "55f25351-2ea2-4156-bac5-01e5b653b195"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 150, 150, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 75, 75, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 73, 73, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 36, 36, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 34, 34, 32)        18464     \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 36992)             0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 57184 (223.38 KB)\n",
            "Trainable params: 57184 (223.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.add(Dense(4096, activation='relu'))\n",
        "model_1.add(Dropout(rate=0.5))\n",
        "\n",
        "model_1.add(Dense(512, activation='relu'))\n",
        "model_1.add(Dropout(rate=0.5))\n",
        "\n",
        "model_1.add(Dense(64, activation='relu'))\n",
        "model_1.add(Dropout(rate=0.5))\n",
        "\n",
        "model_1.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqaGBdc2_mT4",
        "outputId": "4cbac4dd-d232-4d13-c730-f43d251205ec"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 150, 150, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 75, 75, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 73, 73, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 36, 36, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 34, 34, 32)        18464     \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 36992)             0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 4096)              151523328 \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 512)               2097664   \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 64)                32832     \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 153711658 (586.36 MB)\n",
            "Trainable params: 153711658 (586.36 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_1.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        ""
      ],
      "metadata": {
        "id": "Q3UIP-NRAfCW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tr_dtgen = ImageDataGenerator(\n",
        "                              rescale=1. / 255,      # Normalize colour intensities in 0-1 range\n",
        "                              shear_range=0.2,       # Shear varies from 0-0.2\n",
        "                              zoom_range=0.2,\n",
        "                              horizontal_flip=True,\n",
        "                              )"
      ],
      "metadata": {
        "id": "6rbmGK-LBFUF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_generator = tr_dtgen.flow_from_directory(\n",
        "                                               train_data_dir,\n",
        "                                               target_size=(img_width, img_height),\n",
        "                                               batch_size=batch_size,\n",
        "                                               class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EYz5vFGBLwB",
        "outputId": "42a6c199-ca94-4927-b3b2-51aaf63d624d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 989 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dtgen= ImageDataGenerator(rescale=1. / 255)\n"
      ],
      "metadata": {
        "id": "vpKNDL4mBdg-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "validation_generator = val_dtgen.flow_from_directory(\n",
        "                                                     test_data_dir,\n",
        "                                                     target_size=(img_width, img_height),\n",
        "                                                     batch_size=batch_size,\n",
        "                                                     class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VAGndO-BiUx",
        "outputId": "6107039e-99a8-4031-8207-590ab0240d72"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 140 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "history = model_1.fit_generator(\n",
        "                              generator = train_generator,\n",
        "                              steps_per_epoch=nb_train_samples // batch_size,\n",
        "                              epochs=epochs,\n",
        "                              validation_data=validation_generator,\n",
        "                              verbose = 1,\n",
        "                              validation_steps=nb_validation_samples // batch_size\n",
        "                              )\n",
        "\n",
        "end = time.time()\n",
        "(end - start)/60"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj3cFKwzB2OT",
        "outputId": "0dc6002f-3439-4add-9c3a-f1c9568bbb2d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-e20d4a23eed5>:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model_1.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "30/30 [==============================] - 165s 5s/step - loss: 2.5860 - accuracy: 0.1139 - val_loss: 2.2980 - val_accuracy: 0.1328\n",
            "Epoch 2/5\n",
            "30/30 [==============================] - 157s 5s/step - loss: 2.2927 - accuracy: 0.1285 - val_loss: 2.2979 - val_accuracy: 0.1016\n",
            "Epoch 3/5\n",
            "30/30 [==============================] - 156s 5s/step - loss: 2.2937 - accuracy: 0.1421 - val_loss: 2.2882 - val_accuracy: 0.1328\n",
            "Epoch 4/5\n",
            "30/30 [==============================] - 154s 5s/step - loss: 2.2833 - accuracy: 0.1254 - val_loss: 2.2807 - val_accuracy: 0.1641\n",
            "Epoch 5/5\n",
            "30/30 [==============================] - 158s 5s/step - loss: 2.3000 - accuracy: 0.1463 - val_loss: 2.2888 - val_accuracy: 0.1328\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.96287181377411"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "caH_JamxCYmK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}