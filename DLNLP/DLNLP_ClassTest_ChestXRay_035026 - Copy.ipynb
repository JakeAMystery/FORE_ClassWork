{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04adc71f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79069e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1.1 Call libraries for image processing\n",
    "#     Another preprocessing option is text and sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 1.2, Libraries for building sequential CNN model\n",
    "#      A model is composed of sequence of layered objects\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# 1.5 OS related\n",
    "import os, time\n",
    "\n",
    "# 1.6 For ROC plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1.7\n",
    "import numpy as np\n",
    "# conda install scikit-learn\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af23afcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "85364fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Define constants\n",
    "\n",
    "# 2. Our constants\n",
    "# 2.1 Dimensions to which our images will be adjusted\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# 2.2 Data folder containing all training images, maybe in folders: cats and dogs\n",
    "\n",
    "train_data_dir = r\"D:\\chest_xray\\chest_xray\\train\"\n",
    "test_data_dir =  r\"D:\\chest_xray\\chest_xray\\test\"\n",
    "\n",
    "# 2.3 What is the total number of training images\n",
    "#      that should be generated (not what are available)\n",
    "nb_train_samples = 1341+3875   # Actual: 1000 + 1000 (more) =    2000\n",
    "\n",
    "# 2.4 Data folder containing all validation images\n",
    "\n",
    "validation_data_dir = r\"D:\\chest_xray\\chest_xray\\val\"\n",
    "\n",
    "# 2.5 What is the total no of validation samples that should\n",
    "#     be generated?\n",
    "nb_validation_samples = 16   # Actual: 8 + 8 (more) =  16\n",
    "\n",
    "# Some hyperparameters\n",
    "\n",
    "# 2.6 Batch size to train at one go:\n",
    "batch_size = 32             # No of batches = 5216/163 = 32\n",
    "                            # So per epoch we have 32 batches\n",
    "\n",
    "# 2.7 How many epochs of training?\n",
    "epochs = 5                  # For lack of time, let us make it just 5.\n",
    "\n",
    "# 2.8 No of test samples\n",
    "test_generator_samples = 390+234\n",
    "\n",
    "# 2.9 For test data, what should be batch size\n",
    "test_batch_size = 16    # This is different from training batch size\n",
    "\n",
    "# 2.10\n",
    "input_shape = (img_width, img_height, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0112b3a",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b21edcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "063a2e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.add(Input(shape=input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "46881f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.add(Conv2D(\n",
    "    filters=128,\n",
    "    kernel_size= (3,3),\n",
    "    strides = (1,1),\n",
    "    padding='valid',\n",
    "    activation= 'relu'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7f0979c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.add(Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size= (3,3),\n",
    "    strides = (1,1),\n",
    "    activation= 'relu'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "9fd16888",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.add(Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size= (3,3),\n",
    "    activation= 'relu'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "dafa6ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.add(Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size= (4,4),\n",
    "    activation= 'relu'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "99b522bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_59 (Conv2D)          (None, 148, 148, 128)     3584      \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 146, 146, 64)      73792     \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 144, 144, 64)      36928     \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 141, 141, 64)      65600     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,904\n",
      "Trainable params: 179,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "50c13cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_1.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "aead1da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "59a79a4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[1272384,2048] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_46036\\3832215778.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2048\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[0;32m   2099\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnonce\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2100\u001b[0m                 \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateless_fold_in\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnonce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2101\u001b[1;33m             return tf.random.stateless_uniform(\n\u001b[0m\u001b[0;32m   2102\u001b[0m                 \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2103\u001b[0m                 \u001b[0mminval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[1272384,2048] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Mul]"
     ]
    }
   ],
   "source": [
    "model_1.add(Dense(2048, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "7408c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.add(Dense(512, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5578d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.add(Dense(64, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a2d966c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0f8ed405",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_1.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', 'binary_crossentropy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "0000c659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_47 (Conv2D)          (None, 148, 148, 128)     3584      \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 146, 146, 64)      73792     \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 144, 144, 64)      36928     \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 141, 141, 64)      65600     \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 1272384)           0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 256)               325730560 \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 325,951,681\n",
      "Trainable params: 325,951,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee873988",
   "metadata": {},
   "source": [
    "### Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "586601fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tr_dtgen = ImageDataGenerator(\n",
    "                              rescale=1. / 255,      # Normalize colour intensities in 0-1 range\n",
    "                              shear_range=0.2,       # Shear varies from 0-0.2\n",
    "                              zoom_range=0.2,\n",
    "                              horizontal_flip=True,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "56caff79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = tr_dtgen.flow_from_directory(\n",
    "                                               train_data_dir,       # Data folder of cats & dogs\n",
    "                                               target_size=(img_width, img_height),  # Resize images\n",
    "                                               batch_size=batch_size,  # Return images in batches\n",
    "                                               class_mode='binary'   # Output labels will be 1D binary labels\n",
    "                                                                     # [[1],[0],[0],[1]]\n",
    "                                                                     # If 'categorical' output labels will be\n",
    "                                                                     # 2D OneHotEncoded: [[1,0],[0,1],[0,1],[1,0]]\n",
    "                                                                     # If 'binary' use 'sigmoid' at output\n",
    "                                                                     # If 'categorical' use softmax at output\n",
    "\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "4f942d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dtgen= ImageDataGenerator(rescale=1. / 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b3708729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = val_dtgen.flow_from_directory(\n",
    "                                                     validation_data_dir,\n",
    "                                                     target_size=(img_width, img_height),   # Resize images\n",
    "                                                     batch_size=4,    # batch size to augment at a time\n",
    "                                                     class_mode='binary'  # Return 1D array of class labels\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "bcd0619b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubuntu\\AppData\\Local\\Temp\\ipykernel_46036\\3482858202.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model_1.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "163/163 [==============================] - 890s 5s/step - loss: 0.4451 - accuracy: 0.8046 - binary_crossentropy: 0.4451 - val_loss: 0.4664 - val_accuracy: 0.8125 - val_binary_crossentropy: 0.4664\n",
      "Epoch 2/5\n",
      "163/163 [==============================] - 871s 5s/step - loss: 0.2880 - accuracy: 0.8823 - binary_crossentropy: 0.2880 - val_loss: 1.0896 - val_accuracy: 0.7500 - val_binary_crossentropy: 1.0896\n",
      "Epoch 3/5\n",
      " 53/163 [========>.....................] - ETA: 9:46 - loss: 0.3059 - accuracy: 0.8715 - binary_crossentropy: 0.3059"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_46036\\3482858202.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history = model_1.fit_generator(\n\u001b[0m\u001b[0;32m      3\u001b[0m                               \u001b[1;31m# First argument is always data generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                               \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                               \u001b[1;31m# How many batches per epoch?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2634\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m         )\n\u001b[1;32m-> 2636\u001b[1;33m         return self.fit(\n\u001b[0m\u001b[0;32m   2637\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1683\u001b[0m                         ):\n\u001b[0;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1685\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1686\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    924\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m       (concrete_function,\n\u001b[0;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[1;33m     return concrete_function._call_flat(\n\u001b[0m\u001b[0;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1756\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1757\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history = model_1.fit_generator(\n",
    "                              # First argument is always data generator\n",
    "                              generator = train_generator,\n",
    "                              # How many batches per epoch?\n",
    "                              # Can be any number as generator loops indefinitely\n",
    "                              steps_per_epoch=nb_train_samples // batch_size,\n",
    "                              # No of epochs\n",
    "                              epochs=epochs,\n",
    "                              # Get validation data from validation generator\n",
    "                              validation_data=validation_generator,\n",
    "                              verbose = 1,\n",
    "                              validation_steps=nb_validation_samples // 4\n",
    "                              )\n",
    "\n",
    "end = time.time()\n",
    "(end - start)/60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce16a8c",
   "metadata": {},
   "source": [
    "### Model evaluation & Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e15a312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 [======>.......................] - ETA: 1s - loss: 1.1959 - accuracy: 0.5625 - binary_crossentropy: 1.1959WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 4 batches). You may need to use the repeat() function when building your dataset.\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.1959 - accuracy: 0.5625 - binary_crossentropy: 1.1959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1958789825439453, 0.5625, 1.1958789825439453]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model_1.evaluate(\n",
    "                        validation_generator,\n",
    "                        verbose = 1,\n",
    "                        steps = 4        # How many batches\n",
    "                        )\n",
    "\n",
    "\n",
    "# 7.1.1\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d750b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8.0 Make predictions\n",
    "\n",
    "# 8.1 Using generator\n",
    "#     https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict\n",
    "pred = model_1.predict(validation_generator, steps = 2)\n",
    "\n",
    "# 8.1.1\n",
    "pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254bc391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a55b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dtgen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# 9.0.1 Test data\n",
    "\n",
    "test_generator = test_dtgen.flow_from_directory(\n",
    "                                                test_data_dir,\n",
    "                                                # Resize images\n",
    "                                                target_size=(img_width, img_height),\n",
    "                                                # batch size to augment at a time\n",
    "                                                batch_size=batch_size,\n",
    "                                                # Return 1D array of class labels\n",
    "                                                class_mode='binary'\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ff09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9.0.2 Get iterator\n",
    "#       and a batch of (images, image_labels)\n",
    "im = test_generator    # Get iterator\n",
    "images = next(im)      # Get images\n",
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bb80d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9.1 Make predictions\n",
    "results = model_1.predict(images[0])\n",
    "\n",
    "# 9.2 Plot the images and check with\n",
    "#     results\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "plt.figure(figsize= (10,10))\n",
    "for i in range(results.shape[0]):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    _=imshow(images[0][i]) ;\n",
    "\n",
    "plt.show() ;\n",
    "# 9.3 Predicted labels\n",
    "print(results)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b04c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
