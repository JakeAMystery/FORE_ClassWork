{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "620ce1f3",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79069e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1.1 Call libraries for image processing\n",
    "#     Another preprocessing option is text and sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 1.2, Libraries for building sequential CNN model\n",
    "#      A model is composed of sequence of layered objects\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# 1.5 OS related\n",
    "import os, time\n",
    "\n",
    "# 1.6 For ROC plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1.7\n",
    "import numpy as np\n",
    "# conda install scikit-learn\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc998f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "85364fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Define constants\n",
    "\n",
    "# 2. Our constants\n",
    "# 2.1 Dimensions to which our images will be adjusted\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# 2.2 Data folder containing all training images, maybe in folders: cats and dogs\n",
    "\n",
    "train_data_dir = r\"D:\\chest_xray\\chest_xray\\train\"\n",
    "test_data_dir =  r\"D:\\chest_xray\\chest_xray\\test\"\n",
    "\n",
    "# 2.3 What is the total number of training images\n",
    "#      that should be generated (not what are available)\n",
    "nb_train_samples = 1341+3875   # Actual: 1000 + 1000 (more) =    2000\n",
    "\n",
    "# 2.4 Data folder containing all validation images\n",
    "\n",
    "validation_data_dir = r\"D:\\chest_xray\\chest_xray\\val\"\n",
    "\n",
    "# 2.5 What is the total no of validation samples that should\n",
    "#     be generated?\n",
    "nb_validation_samples = 32   # Actual: 8 + 8 (more) =  16\n",
    "\n",
    "# Some hyperparameters\n",
    "\n",
    "# 2.6 Batch size to train at one go:\n",
    "batch_size = 32             # No of batches = 5216/163 = 32\n",
    "                            # So per epoch we have 32 batches\n",
    "\n",
    "# 2.7 How many epochs of training?\n",
    "epochs = 5                  # For lack of time, let us make it just 5.\n",
    "\n",
    "# 2.8 No of test samples\n",
    "test_generator_samples = 390+234\n",
    "\n",
    "# 2.9 For test data, what should be batch size\n",
    "test_batch_size = 16    # This is different from training batch size\n",
    "\n",
    "# 2.10\n",
    "input_shape = (img_width, img_height, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d951f420",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b21edcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "063a2e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.add(Input(shape=input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7f2dae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.add(Conv2D(\n",
    "    filters=256,\n",
    "    kernel_size= (3,3),\n",
    "    strides = (1,1),\n",
    "    padding='valid',\n",
    "    activation= 'relu'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "102aaa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.add(Conv2D(\n",
    "    filters=128,\n",
    "    kernel_size= (3,3),\n",
    "    strides = (1,1),\n",
    "    padding='valid',\n",
    "    activation= 'relu'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e2fd59f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.add(MaxPool2D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ab18adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.add(Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size= (3,3),\n",
    "    activation= 'relu'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "19f2556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.add(MaxPool2D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "44da142b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_26 (Conv2D)          (None, 148, 148, 256)     7168      \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 146, 146, 128)     295040    \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 73, 73, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 71, 71, 64)        73792     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 35, 35, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 376,000\n",
      "Trainable params: 376,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2a433080",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_1.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9ff6f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.add(Dense(128, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5d765cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.add(Dense(64, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "532e9046",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.add(Dropout(rate=0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "79606efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8928ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_1.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', 'binary_crossentropy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "726393ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_26 (Conv2D)          (None, 148, 148, 256)     7168      \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 146, 146, 128)     295040    \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 73, 73, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 71, 71, 64)        73792     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 35, 35, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 78400)             0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 128)               10035328  \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,419,649\n",
      "Trainable params: 10,419,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abb12a9",
   "metadata": {},
   "source": [
    "### Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ae0a349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tr_dtgen = ImageDataGenerator(\n",
    "                              rescale=1. / 255,      # Normalize colour intensities in 0-1 range\n",
    "                              shear_range=0.2,       # Shear varies from 0-0.2\n",
    "                              zoom_range=0.2,\n",
    "                              horizontal_flip=True,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "04d6f8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = tr_dtgen.flow_from_directory(\n",
    "                                               train_data_dir,       # Data folder of cats & dogs\n",
    "                                               target_size=(img_width, img_height),  # Resize images\n",
    "                                               batch_size=batch_size,  # Return images in batches\n",
    "                                               class_mode='binary'   # Output labels will be 1D binary labels\n",
    "                                                                     # [[1],[0],[0],[1]]\n",
    "                                                                     # If 'categorical' output labels will be\n",
    "                                                                     # 2D OneHotEncoded: [[1,0],[0,1],[0,1],[1,0]]\n",
    "                                                                     # If 'binary' use 'sigmoid' at output\n",
    "                                                                     # If 'categorical' use softmax at output\n",
    "\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1e15c75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dtgen= ImageDataGenerator(rescale=1. / 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bea7c70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = val_dtgen.flow_from_directory(\n",
    "                                                     validation_data_dir,\n",
    "                                                     target_size=(img_width, img_height),   # Resize images\n",
    "                                                     batch_size=4,    # batch size to augment at a time\n",
    "                                                     class_mode='binary'  # Return 1D array of class labels\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "36bc9805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubuntu\\AppData\\Local\\Temp\\ipykernel_46036\\1579395863.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model_1.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 60/163 [==========>...................] - ETA: 6:47 - loss: 0.5535 - accuracy: 0.7490 - binary_crossentropy: 0.5535"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_46036\\1579395863.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history = model_1.fit_generator(\n\u001b[0m\u001b[0;32m      3\u001b[0m                               \u001b[1;31m# First argument is always data generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                               \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                               \u001b[1;31m# How many batches per epoch?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2634\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m         )\n\u001b[1;32m-> 2636\u001b[1;33m         return self.fit(\n\u001b[0m\u001b[0;32m   2637\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1683\u001b[0m                         ):\n\u001b[0;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1685\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1686\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    924\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m       (concrete_function,\n\u001b[0;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[1;33m     return concrete_function._call_flat(\n\u001b[0m\u001b[0;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1756\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1757\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history = model_1.fit_generator(\n",
    "                              # First argument is always data generator\n",
    "                              generator = train_generator,\n",
    "                              # How many batches per epoch?\n",
    "                              # Can be any number as generator loops indefinitely\n",
    "                              steps_per_epoch=nb_train_samples // batch_size,\n",
    "                              # No of epochs\n",
    "                              epochs=epochs,\n",
    "                              # Get validation data from validation generator\n",
    "                              validation_data=validation_generator,\n",
    "                              verbose = 1,\n",
    "                              validation_steps=nb_validation_samples // batch_size\n",
    "                              )\n",
    "\n",
    "end = time.time()\n",
    "(end - start)/60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22fac19",
   "metadata": {},
   "source": [
    "### Model evaluation & Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "de9ef991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 [======>.......................] - ETA: 1s - loss: 1.1959 - accuracy: 0.5625 - binary_crossentropy: 1.1959WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 4 batches). You may need to use the repeat() function when building your dataset.\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.1959 - accuracy: 0.5625 - binary_crossentropy: 1.1959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1958789825439453, 0.5625, 1.1958789825439453]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model_1.evaluate(\n",
    "                        validation_generator,\n",
    "                        verbose = 1,\n",
    "                        steps = 4        # How many batches\n",
    "                        )\n",
    "\n",
    "\n",
    "# 7.1.1\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e094f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8.0 Make predictions\n",
    "\n",
    "# 8.1 Using generator\n",
    "#     https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict\n",
    "pred = model_1.predict(validation_generator, steps = 2)\n",
    "\n",
    "# 8.1.1\n",
    "pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb83598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b938413",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dtgen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# 9.0.1 Test data\n",
    "\n",
    "test_generator = test_dtgen.flow_from_directory(\n",
    "                                                test_data_dir,\n",
    "                                                # Resize images\n",
    "                                                target_size=(img_width, img_height),\n",
    "                                                # batch size to augment at a time\n",
    "                                                batch_size=batch_size,\n",
    "                                                # Return 1D array of class labels\n",
    "                                                class_mode='binary'\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145e7205",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9.0.2 Get iterator\n",
    "#       and a batch of (images, image_labels)\n",
    "im = test_generator    # Get iterator\n",
    "images = next(im)      # Get images\n",
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b6f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9.1 Make predictions\n",
    "results = model_1.predict(images[0])\n",
    "\n",
    "# 9.2 Plot the images and check with\n",
    "#     results\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "plt.figure(figsize= (10,10))\n",
    "for i in range(results.shape[0]):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    _=imshow(images[0][i]) ;\n",
    "\n",
    "plt.show() ;\n",
    "# 9.3 Predicted labels\n",
    "print(results)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06bec21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
